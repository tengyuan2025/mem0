# DeepSeek + Mem0 æœ¬åœ°éƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—å±•ç¤ºå¦‚ä½•ä½¿ç”¨ **DeepSeek API** ä½œä¸ºå¤§æ¨¡å‹ï¼Œé…åˆ**æœ¬åœ°å‘é‡å­˜å‚¨**ï¼Œå®ç°å®Œå…¨çš„è®°å¿†æ•°æ®ç§æœ‰åŒ–ã€‚

## ğŸ¯ æ–¹æ¡ˆç‰¹ç‚¹

- **LLM**: DeepSeek APIï¼ˆå¼ºå¤§çš„ä¸­æ–‡ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼‰
- **å‘é‡å­˜å‚¨**: æœ¬åœ° Qdrant/FAISS/Chromaï¼ˆæ•°æ®å®Œå…¨ç§æœ‰ï¼‰
- **åµŒå…¥æ¨¡å‹**: å¤šç§é€‰æ‹©ï¼ˆHuggingFace/OpenAI/Ollamaï¼‰
- **æˆæœ¬**: åªæœ‰ LLM è°ƒç”¨è´¹ç”¨ï¼Œå‘é‡å­˜å‚¨å’ŒåµŒå…¥å…è´¹
- **ğŸŒŸ æ¨è**: Qdrant + HuggingFace ä¸­æ–‡åµŒå…¥ï¼ˆé«˜æ€§èƒ½ + å…è´¹ï¼‰

## ğŸ“‹ å‰ç½®å‡†å¤‡

### 1. DeepSeek API Key
å·²ä¸ºæ‚¨é…ç½®ï¼š`sk-760dd8899ad54634802aafb839f8bda9`

### 2. å®‰è£…ä¾èµ–

```bash
# åŸºç¡€å®‰è£…
pip install mem0ai

# åŒ…å«å‘é‡å­˜å‚¨ä¾èµ–
pip install mem0ai[vector_stores]

# å¦‚æœé€‰æ‹© HuggingFace åµŒå…¥
pip install sentence-transformers

# å¦‚æœé€‰æ‹©æœ¬åœ° FAISS
pip install faiss-cpu  # æˆ– faiss-gpuï¼ˆæœ‰CUDAæ—¶ï¼‰

# Qdrant å‘é‡æ•°æ®åº“ï¼ˆæ¨èé«˜æ€§èƒ½é€‰é¡¹ï¼‰
pip install qdrant-client
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸŒŸ æ–¹æ³•1ï¼šQdrant é«˜æ€§èƒ½ç‰ˆæœ¬ï¼ˆæ¨èï¼‰

```bash
# 1. å¯åŠ¨ Qdrant å‘é‡æ•°æ®åº“
docker run -d --name qdrant \
  -p 6333:6333 -p 6334:6334 \
  -v $(pwd)/qdrant_storage:/qdrant/storage:z \
  qdrant/qdrant

# 2. å®‰è£…ä¾èµ–
pip install mem0ai[vector_stores] sentence-transformers qdrant-client

# 3. å¿«é€Ÿæµ‹è¯•
python quick_start_qdrant.py

# 4. è¿è¡Œå®Œæ•´ç³»ç»Ÿ
python deepseek_qdrant_config.py
```

### æ–¹æ³•2ï¼šFAISS ç®€åŒ–ç‰ˆæœ¬

```bash
# 1. å®‰è£…ä¾èµ–
pip install mem0ai[vector_stores] sentence-transformers

# 2. å¿«é€Ÿæµ‹è¯•  
python quick_start_deepseek.py

# 3. è¿è¡Œå®Œæ•´ç³»ç»Ÿ
python deepseek_chinese_config.py
```

## ğŸ”§ é…ç½®é€‰é¡¹

### ğŸŒŸ æ–¹æ¡ˆ 1: Qdrant + HuggingFace ä¸­æ–‡åµŒå…¥ï¼ˆæ¨èï¼‰

é«˜æ€§èƒ½å‘é‡å­˜å‚¨ + å…è´¹ä¸­æ–‡åµŒå…¥ï¼š

```python
import os
from mem0 import Memory

# è®¾ç½® DeepSeek API Key
os.environ["DEEPSEEK_API_KEY"] = "sk-760dd8899ad54634802aafb839f8bda9"

config = {
    "vector_store": {
        "provider": "qdrant",
        "config": {
            "collection_name": "deepseek_chinese_memories",
            "host": "localhost",
            "port": 6333,
            "embedding_model_dims": 1024,  # BAAI/bge-large-zh-v1.5
            "on_disk": True,  # æŒä¹…åŒ–å­˜å‚¨
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat",
            "temperature": 0.7,
            "max_tokens": 3000,
            "top_p": 0.9,
        },
    },
    "embedder": {
        "provider": "huggingface",
        "config": {
            "model": "BAAI/bge-large-zh-v1.5",  # ä¸­æ–‡è¯­ä¹‰æœ€ä½³
        },
    },
}

m = Memory.from_config(config)
```

### æ–¹æ¡ˆ 2: FAISS + HuggingFace ä¸­æ–‡åµŒå…¥

å®Œå…¨å…è´¹ï¼Œä¸­æ–‡è¯­ä¹‰ç†è§£ä¼˜ç§€ï¼š

```python
import os
from mem0 import Memory

# è®¾ç½® DeepSeek API Key
os.environ["DEEPSEEK_API_KEY"] = "sk-760dd8899ad54634802aafb839f8bda9"

config = {
    "vector_store": {
        "provider": "faiss",
        "config": {
            "collection_name": "deepseek_chinese_memories",
            "path": "./deepseek_faiss_index",
            "embedding_model_dims": 1024,  # BAAI/bge-large-zh-v1.5
            "distance_strategy": "cosine",
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat",
            "temperature": 0.7,
            "max_tokens": 3000,
            "top_p": 0.9,
        },
    },
    "embedder": {
        "provider": "huggingface",
        "config": {
            "model": "BAAI/bge-large-zh-v1.5",  # ä¸­æ–‡è¯­ä¹‰æœ€ä½³
        },
    },
}

m = Memory.from_config(config)
```

### æ–¹æ¡ˆ 2: OpenAI åµŒå…¥ï¼ˆéœ€è¦ OpenAI Keyï¼‰

å¦‚æœæ‚¨æœ‰ OpenAI API Keyï¼Œæ•ˆæœä¹Ÿå¾ˆå¥½ï¼š

```python
# éœ€è¦é¢å¤–è®¾ç½® OpenAI API Key
os.environ["OPENAI_API_KEY"] = "your-openai-key"

config = {
    "vector_store": {
        "provider": "faiss",
        "config": {
            "collection_name": "deepseek_openai_memories",
            "path": "./deepseek_openai_index", 
            "embedding_model_dims": 1536,
            "distance_strategy": "cosine",
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat",
            "temperature": 0.7,
            "max_tokens": 3000,
        },
    },
    "embedder": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small",
        },
    },
}
```

### æ–¹æ¡ˆ 3: Ollama æœ¬åœ°åµŒå…¥

éœ€è¦å…ˆå®‰è£…å’Œè¿è¡Œ Ollamaï¼š

```bash
# å®‰è£… Ollama
brew install ollama  # macOS

# å¯åŠ¨æœåŠ¡
ollama serve

# ä¸‹è½½ä¸­æ–‡åµŒå…¥æ¨¡å‹
ollama pull bge-m3:latest
```

é…ç½®ï¼š
```python
config = {
    "vector_store": {
        "provider": "faiss",
        "config": {
            "collection_name": "deepseek_ollama_memories",
            "path": "./deepseek_ollama_index",
            "embedding_model_dims": 1024,
            "distance_strategy": "cosine",
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat", 
            "temperature": 0.7,
            "max_tokens": 3000,
        },
    },
    "embedder": {
        "provider": "ollama",
        "config": {
            "model": "bge-m3:latest",
            "ollama_base_url": "http://localhost:11434",
        },
    },
}
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¿è¡Œç°æˆçš„è„šæœ¬

```bash
# ä½¿ç”¨ HuggingFace åµŒå…¥ï¼ˆæ¨èï¼Œå®Œå…¨å…è´¹ï¼‰
python deepseek_chinese_config.py

# æˆ–æŒ‡å®šå…¶ä»–é…ç½®
python deepseek_chinese_config.py --config huggingface
python deepseek_chinese_config.py --config ollama
python deepseek_chinese_config.py --config openai
```

### 2. æµ‹è¯•æ‰€æœ‰é…ç½®

```bash
python deepseek_chinese_config.py --test
```

### 3. ç®€å•ä½¿ç”¨ç¤ºä¾‹

```python
from mem0 import Memory
import os

os.environ["DEEPSEEK_API_KEY"] = "sk-760dd8899ad54634802aafb839f8bda9"

# ä½¿ç”¨ HuggingFace é…ç½®
config = {
    "vector_store": {
        "provider": "faiss",
        "config": {
            "collection_name": "test_memories",
            "path": "./test_index",
            "embedding_model_dims": 1024,
            "distance_strategy": "cosine",
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat",
            "temperature": 0.7,
            "max_tokens": 2000,
        },
    },
    "embedder": {
        "provider": "huggingface", 
        "config": {
            "model": "BAAI/bge-large-zh-v1.5",
        },
    },
}

m = Memory.from_config(config)

# æ·»åŠ ä¸­æ–‡è®°å¿†
m.add("æˆ‘æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€æ˜¯Pythonï¼Œç‰¹åˆ«å–œæ¬¢ç”¨å®ƒåšæ•°æ®åˆ†æ", user_id="å¼ ä¸‰")
m.add("æˆ‘ä½åœ¨ä¸Šæµ·ï¼Œæ˜¯ä¸€åAIå·¥ç¨‹å¸ˆ", user_id="å¼ ä¸‰")
m.add("æˆ‘çš„çˆ±å¥½æ˜¯è¯»ä¹¦å’Œè·‘æ­¥ï¼Œå‘¨æœ«ç»å¸¸å»å…¬å›­", user_id="å¼ ä¸‰")

# æœç´¢ç›¸å…³è®°å¿†
results = m.search("Pythonç¼–ç¨‹", user_id="å¼ ä¸‰", limit=3)
print("ç›¸å…³è®°å¿†:")
for r in results["results"]:
    print(f"- {r['memory']} (ç›¸å…³åº¦: {r['score']:.3f})")

# è·å–æ‰€æœ‰è®°å¿†
all_memories = m.get_all(user_id="å¼ ä¸‰")
print(f"\næ€»å…±æœ‰ {len(all_memories['results'])} æ¡è®°å¿†")
```

## ğŸ“Š æ€§èƒ½å’Œæˆæœ¬

### DeepSeek API ä¼˜åŠ¿
- **æˆæœ¬ä½**: è¾“å…¥ Â¥0.14/ä¸‡tokensï¼Œè¾“å‡º Â¥0.28/ä¸‡tokens
- **ä¸­æ–‡ä¼˜ç§€**: ä¸“é—¨ä¼˜åŒ–çš„ä¸­æ–‡ç†è§£èƒ½åŠ›
- **å“åº”å¿«**: å¹³å‡å»¶è¿Ÿè¾ƒä½
- **æ¨¡å‹å¼º**: æ¥è¿‘ GPT-4 çº§åˆ«èƒ½åŠ›

### æœ¬åœ°å‘é‡å­˜å‚¨ä¼˜åŠ¿
- **å®Œå…¨å…è´¹**: å‘é‡å­˜å‚¨å’Œæœç´¢æ— é¢å¤–è´¹ç”¨
- **æ•°æ®ç§æœ‰**: æ•æ„Ÿä¿¡æ¯ä¸ä¼šä¸Šä¼ åˆ°äº‘ç«¯
- **é€Ÿåº¦å¿«**: æœ¬åœ°æ£€ç´¢å»¶è¿Ÿæä½
- **å¯æ§åˆ¶**: å®Œå…¨æ§åˆ¶æ•°æ®å­˜å‚¨å’Œç´¢å¼•

### åµŒå…¥æ¨¡å‹é€‰æ‹©å»ºè®®
| æ–¹æ¡ˆ | è´¹ç”¨ | ä¸­æ–‡æ•ˆæœ | å®‰è£…å¤æ‚åº¦ | æ¨èæŒ‡æ•° |
|------|------|----------|------------|----------|
| HuggingFace | å…è´¹ | â­â­â­â­â­ | â­â­â­ | ğŸ¥‡ æ¨è |
| Ollama | å…è´¹ | â­â­â­â­ | â­â­ | ğŸ¥ˆ ä¸é”™ |  
| OpenAI | ä»˜è´¹ | â­â­â­â­ | â­â­â­â­â­ | ğŸ¥‰ å¤‡é€‰ |

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### 1. HuggingFace æ¨¡å‹ä¸‹è½½æ…¢
```bash
# è®¾ç½®å›½å†…é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```

### 2. FAISS å®‰è£…é—®é¢˜
```bash
# macOS with Apple Silicon
pip install faiss-cpu

# Linux with CUDA
pip install faiss-gpu
```

### 3. DeepSeek API é”™è¯¯
- æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®è®¾ç½®
- ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸
- æ³¨æ„ rate limitï¼ˆæ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶ï¼‰

### 4. ä¸­æ–‡æœç´¢æ•ˆæœä¸å¥½
- ç¡®ä¿ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–çš„åµŒå…¥æ¨¡å‹ï¼ˆå¦‚ bge-large-zh-v1.5ï¼‰
- è®¾ç½® distance_strategy ä¸º "cosine"
- å¢åŠ æœç´¢çš„ limit å‚æ•°

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

### 1. æé«˜ä¸­æ–‡è¯­ä¹‰æœç´¢è´¨é‡
- ä½¿ç”¨å®Œæ•´å¥å­è€Œä¸æ˜¯å•è¯ä½œä¸ºè®°å¿†
- åœ¨è®°å¿†ä¸­åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
- ä½¿ç”¨ä¸€è‡´çš„è¡¨è¾¾æ–¹å¼

### 2. ä¼˜åŒ–å­˜å‚¨ç»“æ„
- æŒ‰ä¸»é¢˜æˆ–æ—¶é—´ç»„ç»‡è®°å¿†
- ä½¿ç”¨ metadata æ·»åŠ æ ‡ç­¾å’Œåˆ†ç±»
- å®šæœŸæ¸…ç†æ— ç”¨çš„è®°å¿†

### 3. æ§åˆ¶æˆæœ¬
- åˆç†è®¾ç½® max_tokens é¿å…è¿‡é•¿ç”Ÿæˆ
- ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹å‡å°‘APIè°ƒç”¨
- æ‰¹é‡å¤„ç†å¤šä¸ªè®°å¿†æ“ä½œ

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰ DeepSeek å‚æ•°
```python
"llm": {
    "provider": "deepseek",
    "config": {
        "model": "deepseek-chat",
        "temperature": 0.7,        # åˆ›é€ æ€§
        "max_tokens": 3000,        # æœ€å¤§è¾“å‡ºé•¿åº¦
        "top_p": 0.9,             # æ ¸é‡‡æ ·
        "frequency_penalty": 0.1,  # é¢‘ç‡æƒ©ç½š
        "presence_penalty": 0.1,   # å­˜åœ¨æƒ©ç½š
    },
}
```

### ğŸ—„ï¸ å‘é‡æ•°æ®åº“é€‰æ‹©

#### æ–¹æ¡ˆ A: Qdrantï¼ˆğŸŒŸ æ¨èé«˜æ€§èƒ½ï¼‰
```python
"vector_store": {
    "provider": "qdrant", 
    "config": {
        "collection_name": "deepseek_memories",
        "host": "localhost",
        "port": 6333,
        "embedding_model_dims": 1024,
        "on_disk": True,  # æŒä¹…åŒ–å­˜å‚¨
    },
}
```

**ä¼˜åŠ¿**: 
- ğŸš€ é«˜æ€§èƒ½å‘é‡æ£€ç´¢
- ğŸ’¾ æ•°æ®æŒä¹…åŒ–
- ğŸ”§ å¯æ‰©å±•åˆ°é›†ç¾¤
- ğŸ“Š Web ç®¡ç†ç•Œé¢

**å¯åŠ¨ Qdrant**:
```bash
docker run -d --name qdrant \
  -p 6333:6333 -p 6334:6334 \
  -v $(pwd)/qdrant_storage:/qdrant/storage:z \
  qdrant/qdrant
```

#### æ–¹æ¡ˆ B: FAISSï¼ˆç®€å•æœ¬åœ°ï¼‰
```python
"vector_store": {
    "provider": "faiss",
    "config": {
        "collection_name": "deepseek_memories",
        "path": "./faiss_index",
        "embedding_model_dims": 1024,
        "distance_strategy": "cosine",
    },
}
```

#### æ–¹æ¡ˆ C: Chromaï¼ˆåŠŸèƒ½ä¸°å¯Œï¼‰
```python
"vector_store": {
    "provider": "chroma",
    "config": {
        "collection_name": "deepseek_memories",
        "path": "./chroma_db",
    },
}
```

è¿™å¥—é…ç½®å¯ä»¥ç»™æ‚¨æœ€ä½³çš„ä¸­æ–‡è®°å¿†ä½“éªŒï¼šDeepSeek çš„å¼ºå¤§ç†è§£èƒ½åŠ› + æœ¬åœ°æ•°æ®å®Œå…¨ç§æœ‰ + ä¸“ä¸šçš„ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼