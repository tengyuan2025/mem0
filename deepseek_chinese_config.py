#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Mem0 + DeepSeek API ä¸­æ–‡ä¼˜åŒ–é…ç½®
æœ¬åœ°å‘é‡å­˜å‚¨ + DeepSeek API LLM + ä¸­æ–‡åµŒå…¥æ¨¡å‹
"""

import os
import sys
from mem0 import Memory

# è®¾ç½® DeepSeek API Key
os.environ["DEEPSEEK_API_KEY"] = "sk-760dd8899ad54634802aafb839f8bda9"

# æ–¹æ¡ˆ1: ä½¿ç”¨ OpenAI åµŒå…¥æ¨¡å‹ï¼ˆéœ€è¦ OpenAI API Keyï¼‰
DEEPSEEK_WITH_OPENAI_EMBEDDINGS = {
    "vector_store": {
        "provider": "faiss",
        "config": {
            "collection_name": "deepseek_chinese_memories",
            "path": "./deepseek_faiss_index",
            "embedding_model_dims": 1536,  # OpenAI text-embedding-3-small
            "distance_strategy": "cosine",
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat",  # æˆ– "deepseek-coder" ç”¨äºä»£ç ç›¸å…³
            "temperature": 0.7,
            "max_tokens": 3000,  # ä¸­æ–‡å†…å®¹é€šå¸¸æ›´é•¿
            "top_p": 0.9,
        },
    },
    "embedder": {
        "provider": "openai", 
        "config": {
            "model": "text-embedding-3-small",  # ä¾¿å®œä¸”æ•ˆæœå¥½
            # å¦‚æœè¦æ›´å¥½æ•ˆæœå¯ä»¥ç”¨: "text-embedding-3-large"
        },
    },
}

# æ–¹æ¡ˆ2: ä½¿ç”¨ HuggingFace ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆå®Œå…¨å…è´¹ï¼‰
DEEPSEEK_WITH_HUGGINGFACE_EMBEDDINGS = {
    "vector_store": {
        "provider": "faiss",
        "config": {
            "collection_name": "deepseek_chinese_memories_hf",
            "path": "./deepseek_hf_index",
            "embedding_model_dims": 1024,  # BAAI/bge-large-zh-v1.5
            "distance_strategy": "cosine",
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat",
            "temperature": 0.7,
            "max_tokens": 3000,
            "top_p": 0.9,
        },
    },
    "embedder": {
        "provider": "huggingface",
        "config": {
            "model": "BAAI/bge-large-zh-v1.5",  # ä¸­æ–‡è¯­ä¹‰ç†è§£æœ€ä½³
            # å¤‡é€‰: "BAAI/bge-base-zh-v1.5" (768ç»´ï¼Œé€Ÿåº¦æ›´å¿«)
        },
    },
}

# æ–¹æ¡ˆ3: ä½¿ç”¨ Ollama æœ¬åœ°åµŒå…¥æ¨¡å‹ï¼ˆéœ€è¦å…ˆå®‰è£…å¹¶è¿è¡Œ Ollamaï¼‰
DEEPSEEK_WITH_OLLAMA_EMBEDDINGS = {
    "vector_store": {
        "provider": "faiss",
        "config": {
            "collection_name": "deepseek_chinese_memories_ollama",
            "path": "./deepseek_ollama_index",
            "embedding_model_dims": 1024,  # bge-m3
            "distance_strategy": "cosine",
        },
    },
    "llm": {
        "provider": "deepseek",
        "config": {
            "model": "deepseek-chat",
            "temperature": 0.7,
            "max_tokens": 3000,
            "top_p": 0.9,
        },
    },
    "embedder": {
        "provider": "ollama",
        "config": {
            "model": "bge-m3:latest",
            "ollama_base_url": "http://localhost:11434",
        },
    },
}


class DeepSeekChineseMemory:
    """DeepSeek + ä¸­æ–‡è®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, config_type="huggingface", user_id="é»˜è®¤ç”¨æˆ·"):
        """
        åˆå§‹åŒ– DeepSeek ä¸­æ–‡è®°å¿†ç³»ç»Ÿ
        
        Args:
            config_type: "openai", "huggingface", "ollama"
            user_id: ç”¨æˆ·æ ‡è¯†
        """
        self.user_id = user_id
        
        # é€‰æ‹©é…ç½®
        configs = {
            "openai": DEEPSEEK_WITH_OPENAI_EMBEDDINGS,
            "huggingface": DEEPSEEK_WITH_HUGGINGFACE_EMBEDDINGS,
            "ollama": DEEPSEEK_WITH_OLLAMA_EMBEDDINGS,
        }
        
        if config_type not in configs:
            raise ValueError(f"é…ç½®ç±»å‹å¿…é¡»æ˜¯: {list(configs.keys())}")
        
        config = configs[config_type]
        
        try:
            self.memory = Memory.from_config(config)
            print(f"âœ“ DeepSeek ä¸­æ–‡è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            print(f"âœ“ ç”¨æˆ·: {user_id}")
            print(f"âœ“ LLM: DeepSeek API")
            print(f"âœ“ åµŒå…¥: {config_type}")
            print(f"âœ“ å‘é‡å­˜å‚¨: æœ¬åœ° FAISS")
        except Exception as e:
            print(f"âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
            if "OPENAI_API_KEY" in str(e) and config_type == "openai":
                print("æç¤º: OpenAI åµŒå…¥éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            elif "ollama" in str(e).lower() and config_type == "ollama":
                print("æç¤º: Ollama åµŒå…¥éœ€è¦å…ˆè¿è¡Œ 'ollama serve' å¹¶ä¸‹è½½æ¨¡å‹")
            sys.exit(1)
        
        self._print_help()
    
    def _print_help(self):
        """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
        print("\n" + "="*60)
        print("DeepSeek + æœ¬åœ°å‘é‡å­˜å‚¨ ä¸­æ–‡è®°å¿†ç³»ç»Ÿ")
        print("="*60)
        print("ç‰¹ç‚¹:")
        print("  â€¢ LLM: DeepSeek API (å¼ºå¤§çš„ä¸­æ–‡ç†è§£å’Œç”Ÿæˆ)")
        print("  â€¢ å­˜å‚¨: æœ¬åœ°å‘é‡æ•°æ®åº“ (æ•°æ®å®Œå…¨ç§æœ‰)")
        print("  â€¢ åµŒå…¥: ä¸­æ–‡ä¼˜åŒ–çš„åµŒå…¥æ¨¡å‹")
        print()
        print("å‘½ä»¤:")
        print("  /è®°å¿† æˆ– /m         - æŸ¥çœ‹æ‰€æœ‰è®°å¿†")
        print("  /æœç´¢ <å…³é”®è¯>      - æœç´¢ç›¸å…³è®°å¿†") 
        print("  /åˆ†æ <æ–‡æœ¬>        - è®© DeepSeek åˆ†ææ–‡æœ¬å¹¶è®°å¿†")
        print("  /å¯¹è¯ <æ¶ˆæ¯>        - åŸºäºè®°å¿†çš„æ™ºèƒ½å¯¹è¯")
        print("  /æ¸…é™¤ æˆ– /c         - æ¸…é™¤æ‰€æœ‰è®°å¿†")
        print("  /ç»Ÿè®¡ æˆ– /s         - æ˜¾ç¤ºè®°å¿†ç»Ÿè®¡")
        print("  /é€€å‡º æˆ– /q         - é€€å‡ºç¨‹åº")
        print("="*60 + "\n")
    
    def add_memory(self, text, metadata=None):
        """æ·»åŠ è®°å¿†"""
        try:
            result = self.memory.add(text, user_id=self.user_id, metadata=metadata)
            print(f"âœ“ è®°å¿†å·²ä¿å­˜")
            return result
        except Exception as e:
            print(f"âœ— ä¿å­˜å¤±è´¥: {e}")
            return None
    
    def search_memories(self, query, limit=5):
        """æœç´¢ç›¸å…³è®°å¿†"""
        try:
            results = self.memory.search(
                query=query,
                user_id=self.user_id,
                limit=limit
            )
            
            if results["results"]:
                print(f"\nğŸ” æ‰¾åˆ° {len(results['results'])} æ¡ç›¸å…³è®°å¿†ï¼š")
                print("-" * 50)
                for i, mem in enumerate(results["results"], 1):
                    score = mem.get('score', 0)
                    memory_text = mem['memory']
                    print(f"{i}. {memory_text}")
                    print(f"   ğŸ’¯ ç›¸å…³åº¦: {score:.3f}")
                    if 'metadata' in mem and mem['metadata']:
                        print(f"   ğŸ·ï¸  æ ‡ç­¾: {mem['metadata']}")
                    print()
            else:
                print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®°å¿†")
            
            return results
        except Exception as e:
            print(f"âœ— æœç´¢å¤±è´¥: {e}")
            return None
    
    def analyze_with_deepseek(self, text):
        """ä½¿ç”¨ DeepSeek åˆ†ææ–‡æœ¬å¹¶ä¿å­˜è®°å¿†"""
        try:
            # æ„é€ åˆ†ææç¤º
            analysis_messages = [
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è®°å¿†åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼Œæå–å…³é”®ä¿¡æ¯ã€ä¸»é¢˜å’Œè¦ç‚¹ï¼Œç„¶åä»¥ç®€æ´æ˜äº†çš„æ–¹å¼æ€»ç»“ã€‚"
                },
                {
                    "role": "user", 
                    "content": f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼š\n\n{text}"
                }
            ]
            
            # ä½¿ç”¨è®°å¿†ç³»ç»Ÿçš„ LLM è¿›è¡Œåˆ†æ
            # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥è®¿é—®å†…éƒ¨ LLMï¼Œå®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦è°ƒæ•´
            print("ğŸ¤– DeepSeek æ­£åœ¨åˆ†æ...")
            
            # ç›´æ¥ä¿å­˜åŸæ–‡æœ¬ä½œä¸ºè®°å¿†
            result = self.add_memory(text, metadata={"type": "analysis"})
            
            # åŒæ—¶æœç´¢ç›¸å…³è®°å¿†
            print("ğŸ” æœç´¢ç›¸å…³è®°å¿†...")
            self.search_memories(text, limit=3)
            
            return result
            
        except Exception as e:
            print(f"âœ— åˆ†æå¤±è´¥: {e}")
            return None
    
    def chat_with_memory(self, message):
        """åŸºäºè®°å¿†çš„æ™ºèƒ½å¯¹è¯"""
        try:
            # æœç´¢ç›¸å…³è®°å¿†
            print("ğŸ” æœç´¢ç›¸å…³è®°å¿†...")
            relevant_memories = self.search_memories(message, limit=3)
            
            # æ„é€ å¸¦è®°å¿†çš„å¯¹è¯
            memory_context = ""
            if relevant_memories and relevant_memories["results"]:
                memory_context = "ç›¸å…³è®°å¿†ï¼š\n"
                for mem in relevant_memories["results"]:
                    memory_context += f"- {mem['memory']}\n"
            
            print(f"\nğŸ’¬ åŸºäº {len(relevant_memories.get('results', []))} æ¡ç›¸å…³è®°å¿†è¿›è¡Œå¯¹è¯")
            print("(æ³¨æ„: å®Œæ•´çš„å¯¹è¯åŠŸèƒ½éœ€è¦å®ç°é¢å¤–çš„ LLM è°ƒç”¨é€»è¾‘)")
            
            # ä¿å­˜æ–°çš„å¯¹è¯è®°å¿†
            self.add_memory(f"ç”¨æˆ·é—®é¢˜: {message}", metadata={"type": "conversation"})
            
        except Exception as e:
            print(f"âœ— å¯¹è¯å¤±è´¥: {e}")
    
    def show_all_memories(self):
        """æ˜¾ç¤ºæ‰€æœ‰è®°å¿†"""
        try:
            memories = self.memory.get_all(user_id=self.user_id)
            
            if memories["results"]:
                print(f"\nğŸ“š å…±æœ‰ {len(memories['results'])} æ¡è®°å¿†ï¼š")
                print("-" * 50)
                for i, mem in enumerate(memories["results"], 1):
                    print(f"{i}. {mem['memory']}")
                    print(f"   ğŸ†” ID: {mem['id'][:12]}...")
                    if 'metadata' in mem and mem['metadata']:
                        print(f"   ğŸ·ï¸  æ ‡ç­¾: {mem['metadata']}")
                    print()
            else:
                print("ğŸ“­ æš‚æ— è®°å¿†")
            
            return memories
        except Exception as e:
            print(f"âœ— è·å–è®°å¿†å¤±è´¥: {e}")
            return None
    
    def show_statistics(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        try:
            memories = self.memory.get_all(user_id=self.user_id)
            total = len(memories["results"])
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            types = {}
            for mem in memories["results"]:
                mem_type = "æ™®é€š"
                if 'metadata' in mem and mem['metadata'] and 'type' in mem['metadata']:
                    mem_type = mem['metadata']['type']
                types[mem_type] = types.get(mem_type, 0) + 1
            
            print(f"\nğŸ“Š è®°å¿†ç»Ÿè®¡:")
            print(f"   æ€»è®¡: {total} æ¡è®°å¿†")
            print(f"   ç±»å‹åˆ†å¸ƒ:")
            for t, count in types.items():
                print(f"     â€¢ {t}: {count} æ¡")
            
        except Exception as e:
            print(f"âœ— ç»Ÿè®¡å¤±è´¥: {e}")
    
    def clear_memories(self):
        """æ¸…é™¤æ‰€æœ‰è®°å¿†"""
        try:
            memories = self.memory.get_all(user_id=self.user_id)
            count = len(memories["results"])
            
            if count == 0:
                print("ğŸ“­ æ²¡æœ‰éœ€è¦æ¸…é™¤çš„è®°å¿†")
                return
            
            confirm = input(f"âš ï¸  ç¡®å®šè¦æ¸…é™¤ {count} æ¡è®°å¿†å—ï¼Ÿ(y/n): ")
            if confirm.lower() in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
                for mem in memories["results"]:
                    self.memory.delete(memory_id=mem['id'])
                print(f"âœ… å·²æ¸…é™¤ {count} æ¡è®°å¿†")
            else:
                print("âŒ å–æ¶ˆæ¸…é™¤")
        except Exception as e:
            print(f"âœ— æ¸…é™¤å¤±è´¥: {e}")
    
    def process_command(self, text):
        """å¤„ç†å‘½ä»¤"""
        text = text.strip()
        
        # é€€å‡º
        if text in ['/é€€å‡º', '/q', '/exit', '/quit']:
            return False
        
        # å¸®åŠ©
        elif text in ['/å¸®åŠ©', '/h', '/help']:
            self._print_help()
        
        # æ˜¾ç¤ºè®°å¿†
        elif text in ['/è®°å¿†', '/m', '/memories']:
            self.show_all_memories()
        
        # ç»Ÿè®¡
        elif text in ['/ç»Ÿè®¡', '/s', '/stats']:
            self.show_statistics()
        
        # æ¸…é™¤è®°å¿†
        elif text in ['/æ¸…é™¤', '/c', '/clear']:
            self.clear_memories()
        
        # æœç´¢è®°å¿†
        elif text.startswith('/æœç´¢') or text.startswith('/search'):
            query = text.replace('/æœç´¢', '').replace('/search', '').strip()
            if query:
                self.search_memories(query)
            else:
                print("âŒ è¯·æä¾›æœç´¢å…³é”®è¯")
        
        # DeepSeek åˆ†æ
        elif text.startswith('/åˆ†æ') or text.startswith('/analyze'):
            content = text.replace('/åˆ†æ', '').replace('/analyze', '').strip()
            if content:
                self.analyze_with_deepseek(content)
            else:
                print("âŒ è¯·æä¾›è¦åˆ†æçš„æ–‡æœ¬")
        
        # å¯¹è¯
        elif text.startswith('/å¯¹è¯') or text.startswith('/chat'):
            message = text.replace('/å¯¹è¯', '').replace('/chat', '').strip()
            if message:
                self.chat_with_memory(message)
            else:
                print("âŒ è¯·æä¾›å¯¹è¯å†…å®¹")
        
        # æ™®é€šè®°å¿†æ·»åŠ 
        elif text and not text.startswith('/'):
            # å…ˆæœç´¢ç›¸å…³è®°å¿†
            print("ğŸ” æœç´¢ç›¸å…³è®°å¿†...")
            self.search_memories(text, limit=3)
            
            # æ·»åŠ æ–°è®°å¿†
            self.add_memory(text)
        
        return True
    
    def run(self):
        """è¿è¡Œäº¤äº’å¾ªç¯"""
        print("ğŸš€ å¼€å§‹ä½¿ç”¨ DeepSeek ä¸­æ–‡è®°å¿†ç³»ç»Ÿï¼ˆè¾“å…¥ /å¸®åŠ© æŸ¥çœ‹å‘½ä»¤ï¼‰")
        
        while True:
            try:
                user_input = input("\nğŸ’­ ä½ : ").strip()
                if not self.process_command(user_input):
                    print("\nğŸ‘‹ å†è§ï¼")
                    break
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")


def test_configs():
    """æµ‹è¯•ä¸åŒé…ç½®çš„å¯ç”¨æ€§"""
    print("ğŸ”§ æµ‹è¯•é…ç½®å¯ç”¨æ€§...")
    
    configs_to_test = [
        ("huggingface", "HuggingFace ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆæ¨èï¼‰"),
        ("ollama", "Ollama æœ¬åœ°åµŒå…¥æ¨¡å‹"), 
        ("openai", "OpenAI åµŒå…¥æ¨¡å‹"),
    ]
    
    available_configs = []
    
    for config_type, desc in configs_to_test:
        try:
            print(f"\næµ‹è¯• {desc}...")
            # è¿™é‡Œåªæ˜¯åˆå§‹åŒ–æµ‹è¯•ï¼Œä¸è¿è¡Œå®Œæ•´ç³»ç»Ÿ
            memory_system = DeepSeekChineseMemory(config_type=config_type)
            print(f"âœ… {desc} å¯ç”¨")
            available_configs.append((config_type, desc))
            del memory_system
        except Exception as e:
            print(f"âŒ {desc} ä¸å¯ç”¨: {e}")
    
    print(f"\nğŸ“‹ å¯ç”¨é…ç½®: {len(available_configs)} ä¸ª")
    for config_type, desc in available_configs:
        print(f"  â€¢ {config_type}: {desc}")
    
    return available_configs


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='DeepSeek + ä¸­æ–‡è®°å¿†ç³»ç»Ÿ')
    parser.add_argument('--config', '-c', 
                       choices=['openai', 'huggingface', 'ollama'],
                       default='huggingface',
                       help='åµŒå…¥æ¨¡å‹é…ç½® (é»˜è®¤: huggingface)')
    parser.add_argument('--user', '-u', default='é»˜è®¤ç”¨æˆ·', help='ç”¨æˆ·ID')
    parser.add_argument('--test', '-t', action='store_true', help='æµ‹è¯•æ‰€æœ‰é…ç½®')
    
    args = parser.parse_args()
    
    if args.test:
        test_configs()
        return
    
    # æ£€æŸ¥ DeepSeek API Key
    if not os.getenv("DEEPSEEK_API_KEY"):
        print("âŒ è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        sys.exit(1)
    
    # å¯åŠ¨è®°å¿†ç³»ç»Ÿ
    try:
        system = DeepSeekChineseMemory(
            config_type=args.config,
            user_id=args.user
        )
        system.run()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ å†è§ï¼")


if __name__ == "__main__":
    main()